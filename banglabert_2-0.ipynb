{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "cuPMS0A9EwTU"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "from transformers import AutoTokenizer, AutoModelForMaskedLM, AutoModelForSequenceClassification, AdamW\n",
        "import os\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "import torch\n",
        "from torch.utils.data import DataLoader, TensorDataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "CovGwGIzFG7K"
      },
      "outputs": [],
      "source": [
        "df=pd.read_excel('merged.xlsx')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S6EGsri2FdR0",
        "outputId": "9ca99408-232f-4ec2-c435-a0d5c6ae8cde"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  articleID          domain             date   category  \\\n",
            "0         0  jagonews24.com  9/19/2018 17:48  Education   \n",
            "1         0  jagonews24.com  9/19/2018 17:48   National   \n",
            "2         3  jagonews24.com  9/19/2018 17:48   National   \n",
            "3         4  jagonews24.com  9/19/2018 17:48      Crime   \n",
            "4         5  jagonews24.com  9/19/2018 17:48   National   \n",
            "\n",
            "                                            headline  \\\n",
            "0   ‡¶π‡¶ü‡ßç‡¶ü‡¶ó‡ßã‡¶≤ ‡¶ï‡¶∞‡¶æ‡ßü ‡¶¨‡¶æ‡¶ï‡ßÉ‡¶¨‡¶ø‡¶§‡ßá ‡¶¶‡ßÅ‡¶á‡¶ú‡¶® ‡¶¨‡¶∞‡¶ñ‡¶æ‡¶∏‡ßç‡¶§, ‡ß¨ ‡¶ú‡¶®‡¶ï‡ßá ‡¶∂‡ßã‡¶ï‡¶ú   \n",
            "1    ‡¶Æ‡¶æ‡¶≤‡ßü‡ßá‡¶∂‡¶ø‡ßü‡¶æ‡ßü ‡¶ï‡¶∞‡ßç‡¶Æ‡ßÄ ‡¶™‡¶æ‡¶†‡¶æ‡¶®‡ßã‡¶∞ ‡¶¨‡ßç‡¶Ø‡¶¨‡¶∏‡ßç‡¶•‡¶æ ‡¶®‡ßá‡ßü‡¶æ‡¶∞ ‡¶∏‡ßÅ‡¶™‡¶æ‡¶∞‡¶ø‡¶∂   \n",
            "2  ‡¶™‡ßç‡¶∞‡ßá‡¶Æ‡ßá‡¶∞ ‡¶™‡ßç‡¶∞‡¶∏‡ßç‡¶§‡¶æ‡¶¨‡ßá ‡¶∞‡¶æ‡¶ú‡¶ø ‡¶®‡¶æ ‡¶π‡¶ì‡ßü‡¶æ‡ßü ‡¶∏‡ßç‡¶ï‡ßÅ‡¶≤‡¶õ‡¶æ‡¶§‡ßç‡¶∞‡ßÄ‡¶ï‡ßá ...   \n",
            "3  ‡¶Æ‡ßá‡¶°‡¶ø‡ßü‡ßá‡¶∂‡¶®‡¶á ‡¶Æ‡¶æ‡¶Æ‡¶≤‡¶æ‡¶ú‡¶ü ‡¶®‡¶ø‡¶∞‡¶∏‡¶®‡ßá‡¶∞ ‡¶™‡¶• : ‡¶¨‡¶ø‡¶ö‡¶æ‡¶∞‡¶™‡¶§‡¶ø ‡¶Ü‡¶π‡¶Æ‡ßá‡¶¶ ...   \n",
            "4         ‡¶ü‡¶ï‡¶∂‡ßã‡¶§‡ßá ‡¶¨‡¶ï‡ßç‡¶§‡¶¨‡ßç‡¶Ø ‡¶¶‡¶ø‡¶§‡ßá ‡¶ó‡¶ø‡ßü‡ßá ‡¶ú‡¶æ‡¶™‡¶æ ‡¶®‡ßá‡¶§‡¶æ‡¶∞ ‡¶Æ‡ßÉ‡¶§‡ßç‡¶Ø‡ßÅ   \n",
            "\n",
            "                                             content label  \n",
            "0  ‡¶ó‡¶§ ‡ßß‡ß≠ ‡¶∏‡ßá‡¶™‡ßç‡¶ü‡ßá‡¶Æ‡ßç‡¶¨‡¶∞ ‡¶¨‡¶æ‡¶Ç‡¶≤‡¶æ‡¶¶‡ßá‡¶∂ ‡¶ï‡ßÉ‡¶∑‡¶ø ‡¶¨‡¶ø‡¶∂‡ßç‡¶¨‡¶¨‡¶ø‡¶¶‡ßç‡¶Ø‡¶æ‡¶≤‡ßü‡ßá ...     0  \n",
            "1  ‡¶¨‡¶æ‡¶Ç‡¶≤‡¶æ‡¶¶‡ßá‡¶∂‡ßá‡¶∞ ‡¶¨‡ßÉ‡¶π‡ßé ‡¶∂‡ßç‡¶∞‡¶Æ‡¶¨‡¶æ‡¶ú‡¶æ‡¶∞ ‡¶Æ‡¶æ‡¶≤‡ßü‡ßá‡¶∂‡¶ø‡ßü‡¶æ‡ßü ‡¶Ü‡¶¨‡¶æ‡¶∞ ‡¶∂‡ßç‡¶∞‡¶Æ...     0  \n",
            "2  ‡¶®‡¶∞‡¶∏‡¶ø‡¶Ç‡¶¶‡ßÄ‡¶∞ ‡¶Æ‡¶®‡ßã‡¶π‡¶∞‡¶¶‡ßÄ‡¶§‡ßá ‡¶™‡ßç‡¶∞‡ßá‡¶Æ‡ßá‡¶∞ ‡¶™‡ßç‡¶∞‡¶∏‡ßç‡¶§‡¶æ‡¶¨‡ßá ‡¶∞‡¶æ‡¶ú‡¶ø ‡¶®‡¶æ ‡¶π...     0  \n",
            "3  ‡¶∏‡ßÅ‡¶™‡ßç‡¶∞‡¶ø‡¶Æ ‡¶ï‡ßã‡¶∞‡ßç‡¶ü‡ßá‡¶∞ ‡¶π‡¶æ‡¶á‡¶ï‡ßã‡¶∞‡ßç‡¶ü ‡¶¨‡¶ø‡¶≠‡¶æ‡¶ó‡ßá‡¶∞ ‡¶¨‡¶ø‡¶ö‡¶æ‡¶∞‡¶™‡¶§‡¶ø ‡¶Ü‡¶π‡¶Æ‡ßá...     0  \n",
            "4  ‡¶Æ‡¶æ‡¶¶‡¶æ‡¶∞‡ßÄ‡¶™‡ßÅ‡¶∞ ‡¶∏‡¶¶‡¶∞‡ßá‡¶∞ ‡¶â‡¶™‡¶ú‡ßá‡¶≤‡¶æ‡¶∞ ‡¶≤‡ßá‡¶ï‡ßá‡¶∞‡¶™‡¶æ‡ßú‡ßá ‡¶è‡¶ï‡¶ü‡¶ø ‡¶¨‡ßá‡¶∏‡¶∞‡¶ï‡¶æ‡¶∞...     0  \n"
          ]
        }
      ],
      "source": [
        "print(df.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gp1BU9XVFf3Y",
        "outputId": "ad80c8da-bc6f-4c7a-a45d-fb26117ada85"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "articleID     98\n",
            "domain        97\n",
            "date         109\n",
            "category     110\n",
            "headline     112\n",
            "content      112\n",
            "label        215\n",
            "dtype: int64\n"
          ]
        }
      ],
      "source": [
        "print(df.isnull().sum())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "oOwArYIdywEA"
      },
      "outputs": [],
      "source": [
        "df['label'] = pd.to_numeric(df['label'], errors='coerce', downcast='integer')\n",
        "df.loc[~df['label'].isin([0, 1]), 'label'] = None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "Hhz68fEEFmsq"
      },
      "outputs": [],
      "source": [
        "df.dropna(subset=['headline','label'],inplace=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L94ZC6vGGMjK"
      },
      "source": [
        "preprocessing start"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "NYzH-mUFFvQN"
      },
      "outputs": [],
      "source": [
        "def preprocess_text(text):\n",
        "  text=re.sub(r'[^a-zA-Z\\u0980-\\u09FF\\s]','',text)\n",
        "  text=re.sub(r'\\s+',' ',text).strip()\n",
        "  return text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "ugb9wI8lGttL"
      },
      "outputs": [],
      "source": [
        "df['clean_headline'] = df['headline'].apply(preprocess_text)\n",
        "df['clean_domain'] = df['domain'].apply(preprocess_text)\n",
        "df['clean_content'] = df['content'].apply(preprocess_text)\n",
        "df['clean_category'] = df['category'].apply(preprocess_text)\n",
        "df['clean_category'] = df['clean_category'].apply(preprocess_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0    ‡¶π‡¶ü‡ßç‡¶ü‡¶ó‡ßã‡¶≤ ‡¶ï‡¶∞‡¶æ‡ßü ‡¶¨‡¶æ‡¶ï‡ßÉ‡¶¨‡¶ø‡¶§‡ßá ‡¶¶‡ßÅ‡¶á‡¶ú‡¶® ‡¶¨‡¶∞‡¶ñ‡¶æ‡¶∏‡ßç‡¶§ ‡ß¨ ‡¶ú‡¶®‡¶ï‡ßá ‡¶∂‡ßã‡¶ï...\n",
            "1    ‡¶Æ‡¶æ‡¶≤‡ßü‡ßá‡¶∂‡¶ø‡ßü‡¶æ‡ßü ‡¶ï‡¶∞‡ßç‡¶Æ‡ßÄ ‡¶™‡¶æ‡¶†‡¶æ‡¶®‡ßã‡¶∞ ‡¶¨‡ßç‡¶Ø‡¶¨‡¶∏‡ßç‡¶•‡¶æ ‡¶®‡ßá‡ßü‡¶æ‡¶∞ ‡¶∏‡ßÅ‡¶™‡¶æ‡¶∞‡¶ø...\n",
            "2    ‡¶™‡ßç‡¶∞‡ßá‡¶Æ‡ßá‡¶∞ ‡¶™‡ßç‡¶∞‡¶∏‡ßç‡¶§‡¶æ‡¶¨‡ßá ‡¶∞‡¶æ‡¶ú‡¶ø ‡¶®‡¶æ ‡¶π‡¶ì‡ßü‡¶æ‡ßü ‡¶∏‡ßç‡¶ï‡ßÅ‡¶≤‡¶õ‡¶æ‡¶§‡ßç‡¶∞‡ßÄ‡¶ï‡ßá ...\n",
            "3    ‡¶Æ‡ßá‡¶°‡¶ø‡ßü‡ßá‡¶∂‡¶®‡¶á ‡¶Æ‡¶æ‡¶Æ‡¶≤‡¶æ‡¶ú‡¶ü ‡¶®‡¶ø‡¶∞‡¶∏‡¶®‡ßá‡¶∞ ‡¶™‡¶• ‡¶¨‡¶ø‡¶ö‡¶æ‡¶∞‡¶™‡¶§‡¶ø ‡¶Ü‡¶π‡¶Æ‡ßá‡¶¶ ‡¶∏‡ßã...\n",
            "4    ‡¶ü‡¶ï‡¶∂‡ßã‡¶§‡ßá ‡¶¨‡¶ï‡ßç‡¶§‡¶¨‡ßç‡¶Ø ‡¶¶‡¶ø‡¶§‡ßá ‡¶ó‡¶ø‡ßü‡ßá ‡¶ú‡¶æ‡¶™‡¶æ ‡¶®‡ßá‡¶§‡¶æ‡¶∞ ‡¶Æ‡ßÉ‡¶§‡ßç‡¶Ø‡ßÅ jag...\n",
            "Name: combined_text, dtype: object\n"
          ]
        }
      ],
      "source": [
        "df['combined_text'] = df['clean_headline'] + ' ' + df['clean_domain'] + ' ' + df['clean_content'] + ' ' + df['clean_category'] + ' ' + df['clean_category']\n",
        "print(df['combined_text'].head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jpQAJBj_UMvL",
        "outputId": "32ed0147-f763-4ea9-9e67-ff85eb74a60f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1740.707194835916\n"
          ]
        }
      ],
      "source": [
        "headline_len=df['clean_content'].apply(len)\n",
        "avg_len=headline_len.mean()\n",
        "print(avg_len)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0rWoleb7UNYP"
      },
      "source": [
        "tokenization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "YUzrg3vTHuxI"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "BertForMaskedLM has generative capabilities, as `prepare_inputs_for_generation` is explicitly overwritten. However, it doesn't directly inherit from `GenerationMixin`. From üëâv4.50üëà onwards, `PreTrainedModel` will NOT inherit from `GenerationMixin`, and this model will lose the ability to call `generate` and other related functions.\n",
            "  - If you're using `trust_remote_code=True`, you can get rid of this warning by loading the model with an auto class. See https://huggingface.co/docs/transformers/en/model_doc/auto#auto-classes\n",
            "  - If you are the owner of the model architecture code, please modify your model class such that it inherits from `GenerationMixin` (after `PreTrainedModel`, otherwise you'll get an exception).\n",
            "  - If you are not the owner of the model architecture class, please contact the model code owner to update it.\n",
            "Some weights of the model checkpoint at sagorsarker/bangla-bert-base were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
            "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        }
      ],
      "source": [
        "tokenizer=AutoTokenizer.from_pretrained('sagorsarker/bangla-bert-base')\n",
        "model=AutoModelForMaskedLM.from_pretrained('sagorsarker/bangla-bert-base')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "M8Xz7VxdPvm9"
      },
      "outputs": [],
      "source": [
        "def tokenize(combined_text, max_length=512):\n",
        "  return tokenizer(combined_text, max_length=max_length, truncation=True, padding='max_length', return_tensors='pt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EalBc2LaS55p",
        "outputId": "fefa004e-aeb9-4310-e8e1-e525787a02b3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Index(['articleID', 'domain', 'date', 'category', 'headline', 'content',\n",
            "       'label', 'clean_headline', 'clean_domain', 'clean_content',\n",
            "       'clean_category', 'combined_text'],\n",
            "      dtype='object')\n"
          ]
        }
      ],
      "source": [
        "print(df.columns)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "tokens=tokenize(df['combined_text'].tolist())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6NrN6JyOXf3q"
      },
      "source": [
        "dataset preparation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "fFyfnhieW8of"
      },
      "outputs": [],
      "source": [
        "x_train,x_test,y_train,y_test=train_test_split(\n",
        "    tokens['input_ids'],df['label'],test_size=0.2,random_state=42\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Aa6xceLLa8x-",
        "outputId": "638c651f-94c3-4366-f151-a6eb6cb7baae"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "x_train shape: torch.Size([39906, 512])\n",
            "x_test shape: torch.Size([9977, 512])\n",
            "y_train shape: (39906,)\n",
            "y_test shape: (9977,)\n"
          ]
        }
      ],
      "source": [
        "print(f\"x_train shape: {x_train.shape}\")\n",
        "print(f\"x_test shape: {x_test.shape}\")\n",
        "print(f\"y_train shape: {y_train.shape}\")\n",
        "print(f\"y_test shape: {y_test.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "QNcs93nybzzc"
      },
      "outputs": [],
      "source": [
        "y_train = torch.tensor(y_train, dtype=torch.long)\n",
        "y_test = torch.tensor(y_test.to_numpy(), dtype=torch.long)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d8l5zixYVtRq",
        "outputId": "5550dfe6-973d-4d2a-91a8-a9758f814400"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_7684\\2854360634.py:1: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  x_train = torch.tensor(x_train)\n",
            "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_7684\\2854360634.py:2: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  x_test = torch.tensor(x_test)\n"
          ]
        }
      ],
      "source": [
        "x_train = torch.tensor(x_train)\n",
        "x_test = torch.tensor(x_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t2yLMrYXWAx-",
        "outputId": "e433da53-eb40-4b17-c8b7-83e369db1403"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "x_train type: <class 'torch.Tensor'>\n",
            "x_train shape: torch.Size([39906, 512])\n"
          ]
        }
      ],
      "source": [
        "print(f\"x_train type: {type(x_train)}\")\n",
        "print(f\"x_train shape: {x_train.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 321
        },
        "id": "6oh1uMWhKGEk",
        "outputId": "e247957c-23fe-4ed7-f866-1a5ac4023200"
      },
      "outputs": [],
      "source": [
        "train_dataset = TensorDataset(x_train, y_train)\n",
        "test_dataset = TensorDataset(x_test, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "GZ37Nu5AKGDp"
      },
      "outputs": [],
      "source": [
        "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=16)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at sagorsarker/bangla-bert-base and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "model=AutoModelForSequenceClassification.from_pretrained(\n",
        "    'sagorsarker/bangla-bert-base', num_labels=2\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Training components"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "optimizer=AdamW(model.parameters(),lr=5e-5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [],
      "source": [
        "loss_fnc=torch.nn.CrossEntropyLoss()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(102025, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0-11): 12 x BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSdpaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "device=torch.device('cuda')\n",
        "model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [],
      "source": [
        "epoch=3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "We strongly recommend passing in an `attention_mask` since your input_ids may be padded. See https://huggingface.co/docs/transformers/troubleshooting#incorrect-output-when-padding-tokens-arent-masked.\n"
          ]
        }
      ],
      "source": [
        "for epoch in range(epoch):\n",
        "    model.train()\n",
        "    total_loss=0\n",
        "    for batch in train_loader:\n",
        "        inputs,labels=batch\n",
        "        inputs, labels=inputs.to(device), labels.to(device)\n",
        "        outputs=model(inputs)\n",
        "        loss=loss_fnc(outputs.logits,labels)\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss+=loss.item()\n",
        "print(f\"EPOCH : {epoch+1}, LOSS:{total_loss/len(train_loader)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [],
      "source": [
        "model.eval()\n",
        "all_preds, all_labels = [], []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [],
      "source": [
        "with torch.no_grad():\n",
        "    for batch in test_loader:\n",
        "        inputs, labels = batch\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        outputs = model(inputs)\n",
        "        preds = torch.argmax(outputs.logits, axis=1)\n",
        "        all_preds.extend(preds.cpu().numpy())\n",
        "        all_labels.extend(labels.cpu().numpy())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ],
      "source": [
        "accuracy = accuracy_score(all_labels, all_preds)\n",
        "precision = precision_score(all_labels, all_preds, average='weighted')\n",
        "recall = recall_score(all_labels, all_preds, average='weighted')\n",
        "f1 = f1_score(all_labels, all_preds, average='weighted')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 0.9737396010824897\n",
            "Precision: 0.9481688107162862\n",
            "Recall: 0.9737396010824897\n",
            "F1 Score: 0.9607840975539699\n"
          ]
        }
      ],
      "source": [
        "print(f\"Accuracy: {accuracy}\")\n",
        "print(f\"Precision: {precision}\")\n",
        "print(f\"Recall: {recall}\")\n",
        "print(f\"F1 Score: {f1}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "('saved_model/banglabert_tokenizer\\\\tokenizer_config.json',\n",
              " 'saved_model/banglabert_tokenizer\\\\special_tokens_map.json',\n",
              " 'saved_model/banglabert_tokenizer\\\\vocab.txt',\n",
              " 'saved_model/banglabert_tokenizer\\\\added_tokens.json',\n",
              " 'saved_model/banglabert_tokenizer\\\\tokenizer.json')"
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.save_pretrained('saved_model/banglabert_model')\n",
        "tokenizer.save_pretrained('saved_model/banglabert_tokenizer')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
